#!/bin/bash

# Nexus AI - ML Infrastructure Startup Script
# Starts all ML infrastructure components for XPress Ops Tower

set -e

echo "ðŸš€ Starting Nexus AI ML Infrastructure..."

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Configuration
REDIS_PORT=${REDIS_PORT:-6379}
POSTGRES_PORT=${POSTGRES_PORT:-5432}
NODE_ENV=${NODE_ENV:-development}
ML_WORKERS=${ML_WORKERS:-2}

# Function to check if a service is running
check_service() {
    local service=$1
    local port=$2
    
    if nc -z localhost $port 2>/dev/null; then
        echo -e "${GREEN}âœ“${NC} $service is running on port $port"
        return 0
    else
        echo -e "${RED}âœ—${NC} $service is not running on port $port"
        return 1
    fi
}

# Function to wait for service
wait_for_service() {
    local service=$1
    local port=$2
    local max_attempts=30
    local attempt=1
    
    echo -e "${YELLOW}Waiting for $service on port $port...${NC}"
    
    while [ $attempt -le $max_attempts ]; do
        if nc -z localhost $port 2>/dev/null; then
            echo -e "${GREEN}âœ“${NC} $service is ready!"
            return 0
        fi
        
        echo -n "."
        sleep 2
        attempt=$((attempt + 1))
    done
    
    echo -e "${RED}âœ—${NC} $service failed to start within $((max_attempts * 2)) seconds"
    return 1
}

# Step 1: Check prerequisites
echo -e "${BLUE}Step 1: Checking prerequisites...${NC}"

# Check if Docker is available
if ! command -v docker &> /dev/null; then
    echo -e "${RED}âœ—${NC} Docker is not installed or not in PATH"
    exit 1
fi

# Check if Node.js is available
if ! command -v node &> /dev/null; then
    echo -e "${RED}âœ—${NC} Node.js is not installed or not in PATH"
    exit 1
fi

# Check if Redis is available (start if needed)
if ! check_service "Redis" $REDIS_PORT; then
    echo -e "${YELLOW}Starting Redis...${NC}"
    if command -v redis-server &> /dev/null; then
        redis-server --daemonize yes --port $REDIS_PORT
        wait_for_service "Redis" $REDIS_PORT
    else
        echo -e "${YELLOW}Starting Redis with Docker...${NC}"
        docker run -d --name xpress-redis -p ${REDIS_PORT}:6379 redis:7-alpine
        wait_for_service "Redis" $REDIS_PORT
    fi
fi

# Step 2: Initialize ML infrastructure
echo -e "${BLUE}Step 2: Initializing ML infrastructure...${NC}"

# Create necessary directories
mkdir -p logs/ml
mkdir -p data/models
mkdir -p data/features
mkdir -p data/events

# Set environment variables
export REDIS_HOST=localhost
export REDIS_PORT=$REDIS_PORT
export NODE_ENV=$NODE_ENV

# Step 3: Start feature store
echo -e "${BLUE}Step 3: Starting Feature Store...${NC}"
cat > /tmp/start-feature-store.js << 'EOF'
const { FeatureStore } = require('./src/lib/ml/store/featureStore.ts');

const featureStore = new FeatureStore({
  redis_url: `redis://localhost:${process.env.REDIS_PORT || 6379}`,
  enable_monitoring: true,
  cache_ttl: 3600,
  batch_size: 1000
});

console.log('Feature Store initialized and ready');
EOF

node -r ts-node/register /tmp/start-feature-store.js &
FEATURE_STORE_PID=$!

# Step 4: Start event processing workers
echo -e "${BLUE}Step 4: Starting Event Processing Workers...${NC}"
for i in $(seq 1 $ML_WORKERS); do
    echo "Starting ML Worker $i..."
    cat > /tmp/ml-worker-$i.js << EOF
const { EventStreamProcessor } = require('./src/lib/ml/streaming/eventStreamProcessor.ts');
const { FeaturePipeline } = require('./src/lib/ml/features/featurePipeline.ts');

const processor = new EventStreamProcessor();
const pipeline = new FeaturePipeline();

console.log('ML Worker $i started and listening for events');

// Keep worker alive
setInterval(() => {
  // Worker heartbeat
  console.log(\`Worker $i heartbeat: \${new Date().toISOString()}\`);
}, 30000);
EOF
    
    node -r ts-node/register /tmp/ml-worker-$i.js &
    echo $! > /tmp/ml-worker-$i.pid
done

# Step 5: Initialize monitoring
echo -e "${BLUE}Step 5: Starting ML Monitoring...${NC}"
cat > /tmp/ml-monitoring.js << 'EOF'
const Redis = require('ioredis');

const redis = new Redis({
  host: process.env.REDIS_HOST || 'localhost',
  port: process.env.REDIS_PORT || 6379
});

// Set up monitoring metrics
const startMonitoring = async () => {
  console.log('Starting ML monitoring...');
  
  // Initialize metrics
  await redis.set('ml:metrics:start_time', new Date().toISOString());
  await redis.set('ml:metrics:events_processed', 0);
  await redis.set('ml:metrics:features_computed', 0);
  await redis.set('ml:metrics:models_served', 0);
  
  // Monitoring loop
  setInterval(async () => {
    const eventsProcessed = await redis.get('ml:metrics:events_processed') || 0;
    const featuresComputed = await redis.get('ml:metrics:features_computed') || 0;
    
    console.log(`ML Metrics - Events: ${eventsProcessed}, Features: ${featuresComputed}`);
  }, 60000); // Log every minute
};

startMonitoring();
EOF

node -r ts-node/register /tmp/ml-monitoring.js &
MONITORING_PID=$!

# Step 6: Health check
echo -e "${BLUE}Step 6: Running health checks...${NC}"
sleep 5

# Check if ML APIs are responding
if curl -s http://localhost:4000/api/ml/events/ingest?check=health > /dev/null; then
    echo -e "${GREEN}âœ“${NC} ML Event Ingestion API is healthy"
else
    echo -e "${YELLOW}âš ${NC} ML Event Ingestion API not yet available (this is normal on first start)"
fi

# Final status
echo -e "${GREEN}"
echo "ðŸŽ‰ Nexus AI ML Infrastructure Started Successfully!"
echo -e "${NC}"
echo "ðŸ“Š Infrastructure Components:"
echo "  â€¢ Redis (Event Queue): localhost:$REDIS_PORT"
echo "  â€¢ Feature Store: Initialized"
echo "  â€¢ Event Processors: $ML_WORKERS workers running"
echo "  â€¢ ML Monitoring: Active"
echo ""
echo "ðŸŒ API Endpoints:"
echo "  â€¢ Event Ingestion: http://localhost:4000/api/ml/events/ingest"
echo "  â€¢ AI Status: http://localhost:4000/api/ai/status"
echo "  â€¢ Nexus Dashboard: http://localhost:4000/nexus"
echo ""
echo "ðŸ“ Logs:"
echo "  â€¢ Application: logs/ml/"
echo "  â€¢ Workers: /tmp/ml-worker-*.log"
echo ""
echo "ðŸ›‘ To stop all services:"
echo "  ./scripts/stop-ml-infrastructure.sh"

# Create stop script
cat > scripts/stop-ml-infrastructure.sh << 'EOF'
#!/bin/bash

echo "ðŸ›‘ Stopping Nexus AI ML Infrastructure..."

# Kill workers
for pid_file in /tmp/ml-worker-*.pid; do
    if [ -f "$pid_file" ]; then
        pid=$(cat "$pid_file")
        if kill -0 "$pid" 2>/dev/null; then
            echo "Stopping ML Worker (PID: $pid)..."
            kill "$pid"
        fi
        rm "$pid_file"
    fi
done

# Kill monitoring
if [ ! -z "$MONITORING_PID" ]; then
    echo "Stopping ML Monitoring..."
    kill $MONITORING_PID 2>/dev/null
fi

# Kill feature store
if [ ! -z "$FEATURE_STORE_PID" ]; then
    echo "Stopping Feature Store..."
    kill $FEATURE_STORE_PID 2>/dev/null
fi

# Clean up temp files
rm -f /tmp/start-feature-store.js
rm -f /tmp/ml-worker-*.js
rm -f /tmp/ml-monitoring.js

echo "âœ“ All ML services stopped"
EOF

chmod +x scripts/stop-ml-infrastructure.sh

# Save PIDs for cleanup
echo $FEATURE_STORE_PID > /tmp/ml-infrastructure.pids
echo $MONITORING_PID >> /tmp/ml-infrastructure.pids

echo -e "${BLUE}âœ¨ Nexus AI is ready for production ML workloads!${NC}"